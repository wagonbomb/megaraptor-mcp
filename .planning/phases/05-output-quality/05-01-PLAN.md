---
phase: 05-output-quality
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/fixtures/baselines/metadata.json
  - tests/fixtures/baselines/linux_sys_users.json
  - tests/fixtures/baselines/generic_client_info.json
  - tests/fixtures/README.md
  - tests/integration/helpers/baseline_helpers.py
autonomous: true

must_haves:
  truths:
    - "Known-good baseline fixtures exist for artifact validation"
    - "Baseline metadata documents hashes and test conditions"
    - "tests/fixtures/README.md documents all baseline datasets"
  artifacts:
    - path: "tests/fixtures/baselines/metadata.json"
      provides: "Central metadata for all baselines"
      contains: "sha256"
    - path: "tests/fixtures/README.md"
      provides: "Known-good dataset documentation"
      contains: "Known-Good Test Datasets"
    - path: "tests/integration/helpers/baseline_helpers.py"
      provides: "Helper functions for baseline operations"
      exports: ["compute_forensic_hash", "load_baseline", "load_baseline_metadata"]
  key_links:
    - from: "tests/integration/helpers/baseline_helpers.py"
      to: "tests/fixtures/baselines/"
      via: "JSON file loading"
      pattern: "tests/fixtures/baselines"
---

<objective>
Create baseline infrastructure for forensic validation testing

Purpose: Establish the known-good baseline fixtures and helper functions that all QUAL-* tests depend on. This provides the foundation for hash validation (QUAL-01), VQL correctness (QUAL-04), and fulfills QUAL-05 (documented test datasets).

Output: Baseline directory with metadata, sample baselines for Linux.Sys.Users and Generic.Client.Info, documented README, and helper functions for baseline operations.
</objective>

<execution_context>
@C:\Users\Meow\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Meow\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-output-quality/05-RESEARCH.md

# Existing patterns
@tests/integration/helpers/wait_helpers.py
@tests/fixtures/README.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create baseline directory structure and helper functions</name>
  <files>
    tests/fixtures/baselines/metadata.json
    tests/fixtures/baselines/linux_sys_users.json
    tests/fixtures/baselines/generic_client_info.json
    tests/integration/helpers/baseline_helpers.py
  </files>
  <action>
Create the baseline infrastructure:

1. Create `tests/fixtures/baselines/` directory

2. Create `tests/integration/helpers/baseline_helpers.py` with:
   - `compute_forensic_hash(data, algorithm='sha256')` - Compute deterministic hash using json.dumps(sort_keys=True, separators=(',', ':'))
   - `load_baseline(artifact_name)` - Load baseline JSON file from baselines/ directory (converts artifact name to filename: Linux.Sys.Users -> linux_sys_users.json)
   - `load_baseline_metadata()` - Load metadata.json
   - `get_baseline_hash(artifact_name)` - Get expected hash from metadata
   - Path constant: `BASELINES_DIR = Path(__file__).parent.parent.parent / "fixtures" / "baselines"`

3. Create `tests/fixtures/baselines/metadata.json` with structure:
```json
{
  "version": "1.0",
  "created": "2026-01-26",
  "description": "Known-good baselines for forensic validation testing",
  "baselines": {
    "Linux.Sys.Users": {
      "filename": "linux_sys_users.json",
      "sha256": null,
      "created": "2026-01-26",
      "test_conditions": {
        "os": "Ubuntu 22.04 Docker container",
        "velociraptor_version": "0.75.x",
        "collection_method": "collect_client with Linux.Sys.Users artifact"
      },
      "critical_fields": ["User", "Uid", "Gid"],
      "notes": "Initial baseline - hash to be populated after first collection"
    },
    "Generic.Client.Info": {
      "filename": "generic_client_info.json",
      "sha256": null,
      "created": "2026-01-26",
      "test_conditions": {
        "os": "Any (cross-platform artifact)",
        "velociraptor_version": "0.75.x",
        "collection_method": "collect_client with Generic.Client.Info artifact"
      },
      "critical_fields": ["Hostname", "OS"],
      "notes": "Initial baseline - hash to be populated after first collection"
    }
  }
}
```

4. Create initial placeholder baseline files:
   - `linux_sys_users.json`: `[]` (empty array, to be populated by baseline collection)
   - `generic_client_info.json`: `[]` (empty array, to be populated by baseline collection)

Note: Initial baselines are placeholders. They will be populated when tests run against live environment and verified manually. This is the correct pattern per research (manual verification before baseline commits).
  </action>
  <verify>
    - `python -c "from tests.integration.helpers.baseline_helpers import compute_forensic_hash, load_baseline, load_baseline_metadata; print('Imports OK')"`
    - `python -c "from tests.integration.helpers.baseline_helpers import compute_forensic_hash; print(compute_forensic_hash({'a': 1, 'b': 2}))"`
    - Files exist: tests/fixtures/baselines/metadata.json, linux_sys_users.json, generic_client_info.json
  </verify>
  <done>
    - compute_forensic_hash() produces deterministic SHA-256 hashes
    - load_baseline() and load_baseline_metadata() load JSON files correctly
    - Baseline directory structure established with metadata and placeholder files
  </done>
</task>

<task type="auto">
  <name>Task 2: Document known-good test datasets in fixtures README</name>
  <files>
    tests/fixtures/README.md
  </files>
  <action>
Update `tests/fixtures/README.md` to document the known-good test datasets (fulfills QUAL-05).

Add a new section "Known-Good Test Datasets" with:

1. Overview of baselines/ directory purpose
2. Documentation for each baseline artifact:
   - Linux.Sys.Users: Purpose, critical fields, expected users (root, nobody), test conditions
   - Generic.Client.Info: Purpose, critical fields, test conditions
3. Baseline Update Procedure:
   1. Collect artifact in controlled environment
   2. Manually verify correctness (compare with source system)
   3. Compute SHA-256 hash of normalized JSON
   4. Document test conditions in metadata.json
   5. Add baseline file to baselines/ directory
   6. Update metadata.json with hash
4. Hash Verification section explaining normalized JSON hashing
5. Note about placeholder vs verified baselines

Keep existing content about config files. Add new section after existing content.

Format following research Pattern 5 (Known-Good Fixture Documentation).
  </action>
  <verify>
    - grep "Known-Good Test Datasets" tests/fixtures/README.md
    - grep "linux_sys_users.json" tests/fixtures/README.md
    - grep "Baseline Update Procedure" tests/fixtures/README.md
  </verify>
  <done>
    - tests/fixtures/README.md contains Known-Good Test Datasets section
    - Documentation covers all baseline artifacts with test conditions
    - Baseline update procedure is documented for future maintainers
    - QUAL-05 requirement satisfied
  </done>
</task>

</tasks>

<verification>
Run verification commands:
```bash
# Verify helper imports work
python -c "from tests.integration.helpers.baseline_helpers import compute_forensic_hash, load_baseline, load_baseline_metadata; print('All imports OK')"

# Verify hash function is deterministic
python -c "from tests.integration.helpers.baseline_helpers import compute_forensic_hash; h1=compute_forensic_hash({'z':1,'a':2}); h2=compute_forensic_hash({'a':2,'z':1}); assert h1==h2, 'Hash should be deterministic regardless of key order'; print('Hash determinism OK')"

# Verify baseline loading
python -c "from tests.integration.helpers.baseline_helpers import load_baseline_metadata; m=load_baseline_metadata(); assert 'baselines' in m; print('Metadata loading OK')"

# Check README documentation
grep -c "Known-Good" tests/fixtures/README.md
```
</verification>

<success_criteria>
- [ ] tests/fixtures/baselines/ directory exists with metadata.json
- [ ] baseline_helpers.py exports compute_forensic_hash, load_baseline, load_baseline_metadata
- [ ] Hash function produces deterministic output (same hash for semantically equal JSON)
- [ ] tests/fixtures/README.md documents all baseline datasets (QUAL-05)
- [ ] Baseline update procedure is documented
</success_criteria>

<output>
After completion, create `.planning/phases/05-output-quality/05-01-SUMMARY.md`
</output>
