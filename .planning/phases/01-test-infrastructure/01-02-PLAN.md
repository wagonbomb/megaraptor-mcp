---
phase: 01-test-infrastructure
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - tests/integration/helpers/__init__.py
  - tests/integration/helpers/wait_helpers.py
  - tests/integration/helpers/cleanup_helpers.py
  - tests/conftest.py
autonomous: true

must_haves:
  truths:
    - "wait_for_flow_completion polls until flow reaches FINISHED state"
    - "wait_for_flow_completion raises TimeoutError if flow does not complete"
    - "wait_for_flow_completion raises RuntimeError if flow reaches ERROR state"
    - "wait_for_client_enrollment returns client_id when client enrolls"
    - "Cleanup fixture archives hunts with TEST- prefix after each test"
    - "Cleanup fixture removes TEST- labels from clients after each test"
  artifacts:
    - path: "tests/integration/helpers/wait_helpers.py"
      provides: "Async operation completion polling"
      exports: ["wait_for_flow_completion", "wait_for_client_enrollment"]
      min_lines: 50
    - path: "tests/integration/helpers/cleanup_helpers.py"
      provides: "Velociraptor entity cleanup utilities"
      exports: ["cleanup_test_hunts", "cleanup_test_labels"]
      min_lines: 30
    - path: "tests/conftest.py"
      provides: "Autouse cleanup fixture"
      contains: "cleanup_velociraptor_state"
  key_links:
    - from: "tests/conftest.py"
      to: "tests/integration/helpers/cleanup_helpers.py"
      via: "cleanup function import"
      pattern: "from tests.integration.helpers.cleanup_helpers import"
    - from: "tests/integration/helpers/wait_helpers.py"
      to: "velociraptor_client.query"
      via: "VQL flow status polling"
      pattern: "flows\\(client_id="
---

<objective>
Create async operation wait helpers and autouse cleanup fixtures to prevent race conditions and state pollution in integration tests.

Purpose: Velociraptor operations are asynchronous - artifact collection flows complete at unpredictable times. Without proper waiting, tests become flaky. Without cleanup, test artifacts accumulate and cause false failures.

Output: wait_helpers.py with polling functions for flow/client enrollment, cleanup_helpers.py with entity cleanup utilities, and autouse cleanup fixture in conftest.py.
</objective>

<execution_context>
@C:\Users\Meow\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Meow\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-test-infrastructure/01-RESEARCH.md

# Dependency - client fixture from Plan 01
@tests/conftest.py
@src/megaraptor_mcp/client.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create wait helpers module</name>
  <files>tests/integration/helpers/__init__.py, tests/integration/helpers/wait_helpers.py</files>
  <action>
Create the helpers directory structure and wait helpers module.

First, create `tests/integration/helpers/__init__.py`:
```python
"""Integration test helpers."""
from .wait_helpers import wait_for_flow_completion, wait_for_client_enrollment
from .cleanup_helpers import cleanup_test_hunts, cleanup_test_labels
```

Then create `tests/integration/helpers/wait_helpers.py`:
```python
"""Wait helpers for async Velociraptor operations.

These helpers poll Velociraptor for operation completion to avoid
race conditions in integration tests.
"""

import time
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from megaraptor_mcp.client import VelociraptorClient


def wait_for_flow_completion(
    client: "VelociraptorClient",
    client_id: str,
    flow_id: str,
    timeout: int = 60,
    poll_interval: int = 2
) -> bool:
    """Wait for a Velociraptor flow to complete.

    Polls the flow status using VQL until it reaches FINISHED state,
    times out, or fails with ERROR state.

    Args:
        client: VelociraptorClient instance
        client_id: Client ID (e.g., "C.123...")
        flow_id: Flow ID (e.g., "F.456...")
        timeout: Maximum wait time in seconds (default 60)
        poll_interval: Time between status checks in seconds (default 2)

    Returns:
        True if flow completed successfully

    Raises:
        TimeoutError: If flow doesn't complete within timeout
        RuntimeError: If flow reaches ERROR state
    """
    start = time.time()

    while time.time() - start < timeout:
        # Query flow status using VQL
        status = client.query(
            f"SELECT state FROM flows(client_id='{client_id}', flow_id='{flow_id}')"
        )

        if status and len(status) > 0:
            state = status[0].get("state", "")
            if state == "FINISHED":
                return True
            elif state == "ERROR":
                raise RuntimeError(f"Flow {flow_id} failed with ERROR state")

        time.sleep(poll_interval)

    raise TimeoutError(f"Flow {flow_id} did not complete within {timeout}s")


def wait_for_client_enrollment(
    client: "VelociraptorClient",
    timeout: int = 60,
    poll_interval: int = 5,
    min_clients: int = 1
) -> str:
    """Wait for at least one Velociraptor client to enroll.

    Polls the clients table until at least min_clients are enrolled.

    Args:
        client: VelociraptorClient instance
        timeout: Maximum wait time in seconds (default 60)
        poll_interval: Time between checks in seconds (default 5)
        min_clients: Minimum number of clients required (default 1)

    Returns:
        Client ID of the first enrolled client

    Raises:
        TimeoutError: If no clients enroll within timeout
    """
    start = time.time()

    while time.time() - start < timeout:
        clients = client.query("SELECT client_id FROM clients() LIMIT 10")

        if len(clients) >= min_clients:
            return clients[0]["client_id"]

        time.sleep(poll_interval)

    raise TimeoutError(f"No clients enrolled within {timeout}s timeout")


def wait_for_hunt_completion(
    client: "VelociraptorClient",
    hunt_id: str,
    timeout: int = 120,
    poll_interval: int = 5
) -> bool:
    """Wait for a hunt to complete (all scheduled clients finished).

    Args:
        client: VelociraptorClient instance
        hunt_id: Hunt ID (e.g., "H.123...")
        timeout: Maximum wait time in seconds (default 120)
        poll_interval: Time between checks in seconds (default 5)

    Returns:
        True if hunt completed

    Raises:
        TimeoutError: If hunt doesn't complete within timeout
    """
    start = time.time()

    while time.time() - start < timeout:
        status = client.query(
            f"SELECT stats FROM hunts(hunt_id='{hunt_id}')"
        )

        if status and len(status) > 0:
            stats = status[0].get("stats", {})
            # Hunt complete when all scheduled clients have finished
            total = stats.get("total_clients_scheduled", 0)
            completed = stats.get("total_clients_with_results", 0)
            if total > 0 and completed >= total:
                return True

        time.sleep(poll_interval)

    raise TimeoutError(f"Hunt {hunt_id} did not complete within {timeout}s")
```
  </action>
  <verify>
Run: `python -c "from tests.integration.helpers.wait_helpers import wait_for_flow_completion, wait_for_client_enrollment; print('OK')"`
Should print OK without import errors.
  </verify>
  <done>
wait_helpers.py exists with wait_for_flow_completion, wait_for_client_enrollment, wait_for_hunt_completion functions.
All functions have proper docstrings and type hints.
Functions are importable.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create cleanup helpers module</name>
  <files>tests/integration/helpers/cleanup_helpers.py</files>
  <action>
Create `tests/integration/helpers/cleanup_helpers.py`:
```python
"""Cleanup helpers for Velociraptor test entities.

These helpers remove test-created entities (hunts, labels) to prevent
state pollution between tests.
"""

from typing import TYPE_CHECKING, List

if TYPE_CHECKING:
    from megaraptor_mcp.client import VelociraptorClient


def cleanup_test_hunts(
    client: "VelociraptorClient",
    test_prefix: str = "TEST-"
) -> List[str]:
    """Archive hunts with test prefix in description.

    Velociraptor doesn't support hunt deletion, so we archive them instead.

    Args:
        client: VelociraptorClient instance
        test_prefix: Prefix to match in hunt_description (default "TEST-")

    Returns:
        List of hunt IDs that were archived
    """
    archived = []

    try:
        # Find hunts with TEST- prefix in description
        test_hunts = client.query(
            f"SELECT hunt_id, hunt_description FROM hunts() "
            f"WHERE hunt_description =~ '{test_prefix}'"
        )

        for hunt in test_hunts:
            hunt_id = hunt.get("hunt_id")
            if hunt_id:
                # Archive the hunt
                client.query(
                    f"SELECT modify_hunt(hunt_id='{hunt_id}', state='ARCHIVED') "
                    f"FROM scope()"
                )
                archived.append(hunt_id)

    except Exception as e:
        # Log but don't fail - cleanup is best-effort
        print(f"Hunt cleanup warning: {e}")

    return archived


def cleanup_test_labels(
    client: "VelociraptorClient",
    label_prefix: str = "TEST-"
) -> List[str]:
    """Remove labels with test prefix from all clients.

    Args:
        client: VelociraptorClient instance
        label_prefix: Prefix to match in labels (default "TEST-")

    Returns:
        List of client IDs that had labels removed
    """
    cleaned = []

    try:
        # Find clients with TEST- prefixed labels
        # Note: VQL array membership check syntax
        labeled_clients = client.query(
            "SELECT client_id, labels FROM clients()"
        )

        for client_data in labeled_clients:
            client_id = client_data.get("client_id")
            labels = client_data.get("labels", [])

            if not client_id or not labels:
                continue

            # Find and remove TEST- prefixed labels
            test_labels = [
                label for label in labels
                if isinstance(label, str) and label.startswith(label_prefix)
            ]

            for label in test_labels:
                client.query(
                    f"SELECT label(client_id='{client_id}', "
                    f"op='remove', labels='{label}') FROM scope()"
                )

            if test_labels:
                cleaned.append(client_id)

    except Exception as e:
        # Log but don't fail - cleanup is best-effort
        print(f"Label cleanup warning: {e}")

    return cleaned


def cleanup_test_flows(
    client: "VelociraptorClient",
    client_id: str,
    flow_prefix: str = "TEST-"
) -> List[str]:
    """Cancel or mark test flows as archived.

    Args:
        client: VelociraptorClient instance
        client_id: Client ID to cleanup flows for
        flow_prefix: Prefix in flow name/artifact (default "TEST-")

    Returns:
        List of flow IDs that were cleaned up

    Note: Flow cleanup is limited - Velociraptor doesn't support flow deletion.
    This function is provided for documentation/future use.
    """
    # Flows cannot be deleted in Velociraptor, only cancelled if running
    # This is a placeholder for future cleanup patterns
    cleaned = []

    try:
        # Query flows for the client
        flows = client.query(
            f"SELECT flow_id, state FROM flows(client_id='{client_id}') "
            f"WHERE state = 'RUNNING'"
        )

        for flow in flows:
            flow_id = flow.get("flow_id")
            if flow_id:
                # Cancel running flows
                client.query(
                    f"SELECT cancel_flow(client_id='{client_id}', "
                    f"flow_id='{flow_id}') FROM scope()"
                )
                cleaned.append(flow_id)

    except Exception as e:
        print(f"Flow cleanup warning: {e}")

    return cleaned
```
  </action>
  <verify>
Run: `python -c "from tests.integration.helpers.cleanup_helpers import cleanup_test_hunts, cleanup_test_labels; print('OK')"`
Should print OK without import errors.
  </verify>
  <done>
cleanup_helpers.py exists with cleanup_test_hunts, cleanup_test_labels, cleanup_test_flows functions.
Functions handle errors gracefully (log and continue, don't fail tests).
Functions are importable.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add autouse cleanup fixture to conftest.py</name>
  <files>tests/conftest.py</files>
  <action>
Add an autouse fixture to conftest.py that runs after each test function to clean up Velociraptor entities.

Add after the existing fixtures:
```python
@pytest.fixture(autouse=True, scope="function")
def cleanup_velociraptor_state(request, velociraptor_client):
    """Clean up Velociraptor entities after each test.

    This autouse fixture runs after every integration test to remove:
    - Hunts with TEST- prefix in description
    - Labels with TEST- prefix from all clients

    Prevents state pollution between tests.
    """
    test_name = request.node.name

    yield  # Test runs here

    # After test: cleanup (only if client is available)
    if velociraptor_client is None:
        return

    try:
        from tests.integration.helpers.cleanup_helpers import (
            cleanup_test_hunts,
            cleanup_test_labels,
        )

        # Archive test hunts
        archived_hunts = cleanup_test_hunts(velociraptor_client, "TEST-")
        if archived_hunts:
            print(f"Cleanup [{test_name}]: Archived {len(archived_hunts)} hunt(s)")

        # Remove test labels
        cleaned_clients = cleanup_test_labels(velociraptor_client, "TEST-")
        if cleaned_clients:
            print(f"Cleanup [{test_name}]: Removed labels from {len(cleaned_clients)} client(s)")

    except ImportError:
        # Helpers not available yet (this is fine during plan execution)
        pass
    except Exception as e:
        # Log cleanup failure but don't fail test
        print(f"Cleanup warning for {test_name}: {e}")
```

IMPORTANT: The cleanup fixture depends on velociraptor_client, which may skip if Docker/configs unavailable. The fixture should handle None gracefully.

Also update the __init__.py import in helpers to not fail if modules don't exist yet:
```python
# tests/integration/helpers/__init__.py
"""Integration test helpers."""
try:
    from .wait_helpers import wait_for_flow_completion, wait_for_client_enrollment
    from .cleanup_helpers import cleanup_test_hunts, cleanup_test_labels
except ImportError:
    # Modules may not exist during initial setup
    pass
```
  </action>
  <verify>
Run: `pytest tests/integration/test_dfir_tools.py -v --timeout=120`
Tests should pass (or skip if Docker unavailable).
Verify cleanup messages appear after tests (if hunts/labels exist).
  </verify>
  <done>
cleanup_velociraptor_state fixture exists in conftest.py.
Fixture is autouse and function-scoped.
Fixture calls cleanup_test_hunts and cleanup_test_labels.
Fixture handles missing dependencies gracefully.
Integration tests still pass.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Helpers importable:
   - `python -c "from tests.integration.helpers.wait_helpers import wait_for_flow_completion; print('OK')"`
   - `python -c "from tests.integration.helpers.cleanup_helpers import cleanup_test_hunts; print('OK')"`

2. Cleanup fixture exists: `grep "cleanup_velociraptor_state" tests/conftest.py` returns match

3. Integration tests pass: `pytest tests/integration/test_dfir_tools.py -v --timeout=120`

4. Manual verification (if Docker running):
   - Start test lab: `./scripts/test-lab.sh up`
   - Run single test: `pytest tests/integration/test_dfir_tools.py::TestClientManagement::test_list_clients -v`
   - Check cleanup runs without errors
</verification>

<success_criteria>
- wait_helpers.py exists with wait_for_flow_completion, wait_for_client_enrollment
- cleanup_helpers.py exists with cleanup_test_hunts, cleanup_test_labels
- conftest.py has autouse cleanup_velociraptor_state fixture
- All helpers are importable without errors
- Integration tests pass or skip appropriately
- Cleanup fixture handles missing dependencies gracefully
</success_criteria>

<output>
After completion, create `.planning/phases/01-test-infrastructure/01-02-SUMMARY.md`
</output>
