---
phase: 04-os-specific-artifacts
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/integration/helpers/target_registry.py
  - tests/integration/schemas/os_artifacts.py
  - tests/integration/test_os_artifacts_linux.py
autonomous: true

must_haves:
  truths:
    - "Linux.Sys.Users artifact collection returns valid user account data"
    - "TargetRegistry can select targets by artifact name"
    - "User data validates against minimal schema (User, Uid, Gid fields present)"
  artifacts:
    - path: "tests/integration/helpers/target_registry.py"
      provides: "get_by_artifact() method for artifact-based target selection"
      contains: "def get_by_artifact"
    - path: "tests/integration/schemas/os_artifacts.py"
      provides: "Linux.Sys.Users JSON schema for validation"
      contains: "LINUX_SYS_USERS_SCHEMA"
    - path: "tests/integration/test_os_artifacts_linux.py"
      provides: "Linux artifact collection tests"
      contains: "test_linux_sys_users"
  key_links:
    - from: "tests/integration/test_os_artifacts_linux.py"
      to: "tests/integration/helpers/target_registry.py"
      via: "get_by_artifact('Linux.Sys.Users')"
      pattern: "get_by_artifact.*Linux"
    - from: "tests/integration/test_os_artifacts_linux.py"
      to: "tests/integration/schemas/os_artifacts.py"
      via: "validate(instance, LINUX_SYS_USERS_SCHEMA)"
      pattern: "validate.*LINUX_SYS_USERS"
---

<objective>
Implement Linux.Sys.Users artifact collection testing with TargetRegistry enhancement and schema validation.

Purpose: Validate OSART-01 (Linux.Sys.Users collection) and OSART-04 (TargetRegistry artifact selection) against live Linux container.
Output: Working Linux artifact tests that collect and validate user data.
</objective>

<execution_context>
@C:\Users\Meow\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\Meow\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-os-specific-artifacts/04-RESEARCH.md

# Existing patterns to follow
@tests/integration/helpers/target_registry.py
@tests/integration/schemas/base_schemas.py
@tests/integration/test_smoke_artifacts.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance TargetRegistry with get_by_artifact() method</name>
  <files>tests/integration/helpers/target_registry.py</files>
  <action>
Add get_by_artifact() method to TargetRegistry class:

```python
def get_by_artifact(self, artifact_name: str) -> Optional[TestTarget]:
    """Get first target that supports a specific artifact.

    Maps artifact names to OS capabilities:
    - Linux.* -> Linux target
    - Windows.Registry.* -> Windows target with registry capability
    - Windows.* -> Windows target
    - Generic.* -> Any target

    Args:
        artifact_name: Full artifact name (e.g., 'Linux.Sys.Users')

    Returns:
        TestTarget that supports the artifact, or None
    """
    if artifact_name.startswith("Linux."):
        return self.get_by_os("linux")
    elif artifact_name.startswith("Windows.Registry."):
        return self.get_by_capability("windows_registry")
    elif artifact_name.startswith("Windows."):
        return self.get_by_os("windows")
    elif artifact_name.startswith("Generic."):
        # Generic artifacts work on any OS
        return self.targets[0] if self.targets else None
    else:
        # Unknown prefix - try any target
        return self.targets[0] if self.targets else None
```

Also add `windows_services` to WINDOWS_CAPABILITIES list if not present:
```python
WINDOWS_CAPABILITIES = [
    "generic_artifacts",
    "windows_registry",
    "windows_prefetch",
    "windows_eventlog",
    "windows_filesystem",
    "windows_processes",
    "windows_services",  # Add this
]
```

Update imports to include Optional from typing if not already present.
  </action>
  <verify>
Run: `python -c "from tests.integration.helpers.target_registry import TargetRegistry; r = TargetRegistry(); print('get_by_artifact' in dir(r))"`
Should print: True
  </verify>
  <done>TargetRegistry has get_by_artifact() method that maps artifact names to OS targets</done>
</task>

<task type="auto">
  <name>Task 2: Create OS-specific artifact schemas</name>
  <files>tests/integration/schemas/os_artifacts.py</files>
  <action>
Create new file tests/integration/schemas/os_artifacts.py with minimal schemas following the established pattern from base_schemas.py (minimal required fields, no additionalProperties: false):

```python
"""OS-specific artifact JSON schemas for validation.

Schemas validate only critical fields - keep minimal to avoid brittleness.
Do NOT use additionalProperties: false - allow new fields across versions.

Field types accept both string and integer where VQL may return either.
"""

# Linux artifact schemas

LINUX_SYS_USERS_SCHEMA = {
    "type": "array",
    "items": {
        "type": "object",
        "required": ["User"],  # Only most critical field required
        "properties": {
            "User": {"type": "string"},
            "Uid": {"type": ["string", "integer"]},  # May be string or int
            "Gid": {"type": ["string", "integer"]},
            "Homedir": {"type": "string"},
            "Shell": {"type": "string"},
            "Description": {"type": "string"},
        }
    }
}


# Windows artifact schemas (for future Windows target testing)

WINDOWS_SYSTEM_SERVICES_SCHEMA = {
    "type": "array",
    "items": {
        "type": "object",
        "required": ["Name"],  # Only most critical field required
        "properties": {
            "Name": {"type": "string"},
            "DisplayName": {"type": "string"},
            "State": {"type": "string"},
            "PathName": {"type": "string"},
            "ServiceDll": {"type": "string"},
            "AbsoluteExePath": {"type": "string"},
        }
    }
}


WINDOWS_REGISTRY_USERASSIST_SCHEMA = {
    "type": "array",
    "items": {
        "type": "object",
        # UserAssist may return empty results - no required fields
        # When results exist, validate structure
        "properties": {
            "_KeyPath": {"type": "string"},
            "Name": {"type": "string"},  # ROT13-decoded application name
            "User": {"type": "string"},
            "LastExecution": {"type": "string"},  # Timestamp string
            "NumberOfExecutions": {"type": ["integer", "string"]},
        }
    }
}
```

Also update tests/integration/schemas/__init__.py to export these schemas:
```python
from .os_artifacts import (
    LINUX_SYS_USERS_SCHEMA,
    WINDOWS_SYSTEM_SERVICES_SCHEMA,
    WINDOWS_REGISTRY_USERASSIST_SCHEMA,
)
```
  </action>
  <verify>
Run: `python -c "from tests.integration.schemas.os_artifacts import LINUX_SYS_USERS_SCHEMA; print(LINUX_SYS_USERS_SCHEMA['items']['required'])"`
Should print: ['User']
  </verify>
  <done>OS-specific schemas exist with minimal required fields following established patterns</done>
</task>

<task type="auto">
  <name>Task 3: Implement Linux.Sys.Users collection test</name>
  <files>tests/integration/test_os_artifacts_linux.py</files>
  <action>
Create new file tests/integration/test_os_artifacts_linux.py following patterns from test_smoke_artifacts.py:

```python
"""Linux OS-specific artifact collection tests.

Validates:
- OSART-01: Linux.Sys.Users artifact collection and validation works

Uses the existing Docker container with Linux client for testing.
"""

import pytest
from jsonschema import validate, ValidationError
from pytest_check import check

from tests.integration.helpers.wait_helpers import wait_for_flow_completion
from tests.integration.schemas.os_artifacts import LINUX_SYS_USERS_SCHEMA


@pytest.mark.integration
@pytest.mark.timeout(60)
class TestLinuxArtifacts:
    """Linux-specific artifact collection tests."""

    def test_linux_sys_users_collection(self, velociraptor_client, target_registry):
        """Test Linux.Sys.Users artifact collection and validation.

        Validates OSART-01: Linux.Sys.Users artifact collection returns
        valid user account data from Linux targets.

        This test:
        1. Selects Linux target via TargetRegistry
        2. Schedules Linux.Sys.Users artifact collection
        3. Waits for flow completion
        4. Validates results against JSON schema
        5. Verifies critical user fields are present and typed correctly
        """
        # Get Linux target using new get_by_artifact method (validates OSART-04)
        target = target_registry.get_by_artifact("Linux.Sys.Users")
        if not target:
            pytest.skip("No Linux target available for Linux.Sys.Users")

        # Verify we got a Linux target
        assert target.os_type == "linux", \
            f"Expected Linux target, got {target.os_type}"

        client_id = target.client_id

        # Schedule artifact collection
        vql = f"""
        SELECT collect_client(
            client_id='{client_id}',
            artifacts=['Linux.Sys.Users'],
            timeout=30
        ) AS collection
        FROM scope()
        """

        result = velociraptor_client.query(vql)

        # Validate collection was scheduled
        with check:
            assert len(result) > 0, "collect_client returned no results"

        collection = result[0].get("collection", {})
        flow_id = collection.get("flow_id")

        if not flow_id:
            pytest.fail("No flow_id returned from collect_client")

        # Wait for flow completion
        try:
            wait_for_flow_completion(
                velociraptor_client,
                client_id,
                flow_id,
                timeout=30
            )
        except TimeoutError:
            pytest.fail("Linux.Sys.Users collection did not complete in 30s")

        # Get flow results
        # Linux.Sys.Users does not have sub-sources (unlike Generic.Client.Info)
        results_vql = f"""
        SELECT * FROM source(
            client_id='{client_id}',
            flow_id='{flow_id}',
            artifact='Linux.Sys.Users'
        )
        """
        results = velociraptor_client.query(results_vql)

        # Validate results against JSON schema
        try:
            validate(instance=results, schema=LINUX_SYS_USERS_SCHEMA)
        except ValidationError as e:
            pytest.fail(f"Schema validation failed: {e.message}")

        # Validate we got user data
        with check:
            assert len(results) > 0, "Linux.Sys.Users returned no users"

        if results:
            user = results[0]

            # Verify critical fields present with flexible matching
            # Field names established from Velociraptor docs
            user_found = any(k in user for k in ["User", "user", "Username", "username"])
            uid_found = any(k in user for k in ["Uid", "uid", "UID"])
            gid_found = any(k in user for k in ["Gid", "gid", "GID"])

            with check:
                assert user_found, \
                    f"Missing user field. Available: {list(user.keys())}"
            with check:
                assert uid_found, \
                    f"Missing UID field. Available: {list(user.keys())}"
            with check:
                assert gid_found, \
                    f"Missing GID field. Available: {list(user.keys())}"

            # Validate User field type and value
            user_key = next((k for k in ["User", "user", "Username", "username"] if k in user), None)
            if user_key:
                with check:
                    assert isinstance(user[user_key], str), \
                        f"User should be string, got {type(user[user_key])}"
                with check:
                    assert len(user[user_key]) > 0, "User field is empty"

            # Linux container should have at least root user
            usernames = [
                r.get("User", r.get("user", r.get("Username", "")))
                for r in results
            ]
            with check:
                assert any(u == "root" for u in usernames), \
                    f"Expected 'root' user in results. Found: {usernames[:5]}"

        # Validate we have reasonable number of users
        # Docker containers typically have at least root, nobody, etc.
        with check:
            assert len(results) >= 1, \
                f"Expected at least 1 user, got {len(results)}"


    def test_target_registry_get_by_artifact(self, target_registry):
        """Test TargetRegistry.get_by_artifact() method.

        Validates OSART-04: TargetRegistry selects appropriate test targets
        based on artifact capabilities.
        """
        # Linux artifacts should return Linux target
        linux_target = target_registry.get_by_artifact("Linux.Sys.Users")
        if linux_target:
            with check:
                assert linux_target.os_type == "linux", \
                    f"Linux artifact should select Linux target, got {linux_target.os_type}"
            with check:
                assert "linux_users" in linux_target.capabilities, \
                    f"Linux target missing linux_users capability: {linux_target.capabilities}"

        # Windows artifacts should return Windows target (or None if unavailable)
        windows_target = target_registry.get_by_artifact("Windows.System.Services")
        if windows_target:
            with check:
                assert windows_target.os_type == "windows", \
                    f"Windows artifact should select Windows target, got {windows_target.os_type}"

        # Windows.Registry artifacts should check registry capability
        registry_target = target_registry.get_by_artifact("Windows.Registry.UserAssist")
        if registry_target:
            with check:
                assert registry_target.os_type == "windows", \
                    f"Registry artifact should select Windows target, got {registry_target.os_type}"
            with check:
                assert "windows_registry" in registry_target.capabilities, \
                    f"Registry target missing windows_registry capability"

        # Generic artifacts should return any target
        generic_target = target_registry.get_by_artifact("Generic.Client.Info")
        with check:
            assert generic_target is not None, \
                "Generic.Client.Info should return a target (any OS works)"
```

Key patterns followed:
- Module structure matches test_smoke_artifacts.py
- Uses pytest_check for soft assertions
- Uses flexible field name matching for version resilience
- 60-second timeout for artifact collection
- Proper source() VQL syntax (no sub-source needed for Linux.Sys.Users)
  </action>
  <verify>
Run: `pytest tests/integration/test_os_artifacts_linux.py -v --tb=short -x`
All tests should pass (Linux target available in Docker container)
  </verify>
  <done>Linux.Sys.Users collection test passes against live container, validates OSART-01 and OSART-04</done>
</task>

</tasks>

<verification>
1. TargetRegistry enhancement: `python -c "from tests.integration.helpers.target_registry import TargetRegistry; r = TargetRegistry(); print('get_by_artifact' in dir(r))"`
2. Schema import: `python -c "from tests.integration.schemas.os_artifacts import LINUX_SYS_USERS_SCHEMA; print('success')"`
3. Full test run: `pytest tests/integration/test_os_artifacts_linux.py -v --tb=short`
4. Combined with existing tests: `pytest tests/integration/ -v --tb=short -x` (no regressions)
</verification>

<success_criteria>
- [ ] TargetRegistry.get_by_artifact() exists and maps Linux.* to Linux targets
- [ ] LINUX_SYS_USERS_SCHEMA validates with minimal required fields
- [ ] test_linux_sys_users_collection passes against live container
- [ ] test_target_registry_get_by_artifact validates artifact-to-capability mapping
- [ ] All existing tests continue to pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/04-os-specific-artifacts/04-01-SUMMARY.md`
</output>
